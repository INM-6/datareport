from urllib.parse import urlencode, urlunparse
from urllib.request import urlopen
import os.path
import re

configfile: 'config.yaml'
reporter = "../../datareport/reporter.py"   # this should just be "reporter"

def makeSearch(searchparameters, of='hx', sf='year', rg='', so='d'):
    ' creates a lambda expression to fill wildcards into a juser query URL '
    return lambda wc: urlunparse(
        [ 'https', 'juser.fz-juelich.de', '/PubExporter.py', '',
          urlencode({'of': of, 'p': searchparameters.format(wc=wc),
                     'sf': sf, 'rg':rg, 'so': so}),
          '',
        ])

def data(name):
    ' returns a full filename to the datafile with given name '
    return os.path.join(config['datadir'], name.lstrip('/'))

def report(name):
    return os.path.join(config['outdir'], name.lstrip('/'))

def report_html(name):
    return os.path.join(config['outdir_html'], name.lstrip('/'))


rule all:
    input:
        report_html('AuthorList.html'),
        report_html('PublicationsList_2017.html'),


rule mkhtml:
    input:
        files=[report('{name}.md')],
        css=report_html('document.css'),
    output:
        report_html('{name}.html'),
    shell:
        '''
        pandoc -f markdown+simple_tables+multiline_tables -t html --css "$(basename "{input.css}")" -o {output} {input.files}
        '''

rule copy_css:
    ' this rule copies the style sheet to the HTML destination folder '
    output:
        '{path}/{name}.css',
    input:
        '{name}.css',
    shell:
        'cp -iv {input} {output}'


rule AuthorList:
    '''
    This rule renders the authors database into a nicely formatted MARKDOWN
    file using the data downloaded before and the given template.
    '''
    input:
        'templates/AuthorList.md',
        list= 'data/juser_authors_2017.yaml',
    output:
        report('AuthorList.md')
    run:
        shell('%(reporter)s -t %(template)s -o %(output)s %(datadef)s' % {
            'reporter': reporter,
            'template': input[0],
            'datadef': " ".join(["%s=%s" % kv for kv in input.items()]),
            'output': output[0],
        })


rule PublicationsList:
    '''
    This rule renders the publications database into a nicely formatted MARKDOWN
    file using the data downloaded before and the given template.
    '''
    input:
        'templates/PublicationsList.md',
        authors = 'data/juser_authors_{year}.yaml',
        publications = 'data/juser_publications_{year}.yaml',
    output:
        report('PublicationsList_{year}.md')
    run:
        shell('%(reporter)s -t %(template)s -o %(output)s %(datadef)s' % {
            'reporter': reporter,
            'template': input[0],
            'datadef': " ".join(["%s=%s" % kv for kv in input.items()]),
            'output': output[0],
        })


rule fetchall:
    input:
        expand(data('juser_{info}_{year}.yaml'),
            info=config['infos'],
            year=config['years'],
        )

rule fetch_juser:
    '''
    This is a generic rule to fetch data from the juser.fz-juelich.de server.
    The query is currently defined by the 'params' section and has the 'year'
    as wildcard. Like this it is easy to let snakemake figure out how many
    queries to do...

    The juser query result is in BibTeX format and needs to be reformated to
    YAML. This rule therefore automatically pipes everything through
    `pandoc-citeproc` before writing the output file.

    You might need to be logged in in your browser for this to work.
    '''
    output:
        data('juser_publications_{year,\d{4}}.yaml')
    params:
        search= makeSearch('cid:"I:(DE-Juel1)INM-6-20090406" AND prg:"G:(EU-Grant)720270" AND pub:"{wc.year}"'),
    shell:
        '''
        curl '{params.search}' |\
            pandoc-citeproc --bib2yaml --format=bibtex /dev/stdin |\
            cat >'{output}'
        '''

rule fetch_authors:
    '''
    Fetch all authors and their ids from the Juser database. You need to have
    access to the relevant data, of course.

    This rule produces the data file that is used for creating the report.
    '''
    output:
        data('juser_authors_{year,\d{4}}.yaml')
    params:
        search = makeSearch('cid:"I:(DE-Juel1)INM-6-20090406" AND prg:"G:(EU-Grant)720270" AND pub:"{wc.year}"', of='al'),
    run:
        from ruamel import yaml
        authors = dict()
        infos = re.compile(r'(?P<family>[^,\[]+),? ?(?P<given>[^\[]*) \[P:\((?P<registry>[^)]+)\)(?P<id>[^\]]+)\]')
        with urlopen(params.search) as infile:
            for line in infile:
                for author in line.decode("utf8").split(";"):
                    match = infos.match(author.strip())
                    if match is None:
                        print("Offending line: "+author)
                    else:
                        alt = authors.setdefault("{family}, {given}".format(**match.groupdict()), list())
                        data = dict(match.groupdict())
                        if data not in alt:
                            alt.append(data)
        yaml.dump(authors, open(output[0], 'w'))

